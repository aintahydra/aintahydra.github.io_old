<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>wrting-python-crawlers | aintahydra - dont talk shit</title>
  <meta name="author" content="aintahydra">
  
  <meta name="description" content="Install required packages$ sudo apt install python-pip
$ pip scrapy lxml
Create a project$ scrapy startproject crawling_apt
$  tree crawling_apt/
craw">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="wrting-python-crawlers"/>
  <meta property="og:site_name" content="aintahydra - dont talk shit"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="aintahydra - dont talk shit" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">aintahydra - dont talk shit</a></h1>
  <h2><a href="/">They seemed to insist upon his being but a mere __daily breader__,&#34; who was trudging home to snatch a few hours&#39; sleep before hurrying off to catch the train to his work. -- _Horace W. C. Newte, The Square Mile, A Story of Ways and Means, 1908_</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-11-08T05:11:30.000Z"><a href="/2017/11/08/wrting-python-crawlers/">2017-11-08</a></time>
      
      
  
    <h1 class="title">wrting-python-crawlers</h1>
  

    </header>
    <div class="entry">
      
        <h1 id="Install-required-packages"><a href="#Install-required-packages" class="headerlink" title="Install required packages"></a>Install required packages</h1><pre><code>$ sudo apt install python-pip
$ pip scrapy lxml
</code></pre><h1 id="Create-a-project"><a href="#Create-a-project" class="headerlink" title="Create a project"></a>Create a project</h1><pre><code>$ scrapy startproject crawling_apt
$  tree crawling_apt/
crawling_apt/
├── crawling_apt ( name of this project0)
│   ├── __init__.py
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg
</code></pre><p>Now a crawler can be written under the ‘spider’ folder, like:</p>
<pre><code>$ cd crawling_apt
$ EDIT crawling_apt/spiders/AHoppingSpider.py
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"><span class="comment">#-*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="comment"># to execute</span></div><div class="line"><span class="comment"># ~/python/mycrawler/crawling_apt$ scrapy crawl ahopper</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"><span class="keyword">from</span> listitem <span class="keyword">import</span> InfoListItem</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">AHoppingSpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    name = <span class="string">"ahopper"</span></div><div class="line">    allowed_domains = [<span class="string">"apt2you.com"</span>]</div><div class="line">    start_urls = [</div><div class="line">        <span class="string">"https://www.apt2you.com/"</span>,</div><div class="line">    ]</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></div><div class="line">        <span class="keyword">return</span> scrapy.Request(</div><div class="line">            url = <span class="string">"https://www.apt2you.com/houseSaleSimpleInfo.do"</span>,</div><div class="line">            callback = self.parse_notice</div><div class="line">        )</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_notice</span><span class="params">(self, response)</span>:</span></div><div class="line"></div><div class="line">        <span class="comment">## just save the whole HTML page to a local file </span></div><div class="line">        <span class="comment">#page = response.url.split("/")[-2]</span></div><div class="line">        <span class="comment">#filename = 'ahopper-%s.html' % page </span></div><div class="line">        <span class="comment">#with open(filename, 'wb') as f :</span></div><div class="line">        <span class="comment">#    f.write(response.body)</span></div><div class="line"></div><div class="line">        rows = response.xpath(<span class="string">'//table[@class="tbl_default sortable"]/tbody/tr'</span>)</div><div class="line"></div><div class="line">        items = []</div><div class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> rows:</div><div class="line">            item = InfoListItem()</div><div class="line">            </div><div class="line">            area = row.xpath(<span class="string">'td[1]/text()'</span>).extract()</div><div class="line">            <span class="comment"># aptname, constructor, applydates below are the same type</span></div><div class="line">            aptname = row.xpath(<span class="string">'td[2]//u/text()'</span>).extract()</div><div class="line">            constructor = row.xpath(<span class="string">'td[3]/text()'</span>).extract()</div><div class="line">            applydates = row.xpath(<span class="string">'td[4]/text()'</span>).extract()</div><div class="line">            <span class="comment"># now area is a list of unicode. type(area) is 'list'</span></div><div class="line"></div><div class="line">            strarea = area[<span class="number">0</span>].encode(<span class="string">"UTF-8"</span>)</div><div class="line">            <span class="comment"># now strarea is a string contains UTF-8 characters</span></div><div class="line">            straptname = aptname[<span class="number">0</span>].encode(<span class="string">"UTF-8"</span>)</div><div class="line">            strconstructor = constructor[<span class="number">0</span>].encode(<span class="string">"UTF-8"</span>)</div><div class="line">            strapplydates = <span class="string">""</span>.join(applydates[<span class="number">0</span>].encode(<span class="string">"UTF-8"</span>).split())</div><div class="line"></div><div class="line">	    tup = (strarea, straptname, strconstructor, strapplydates)</div><div class="line">                                       </div><div class="line">            items.append(tup)</div><div class="line"></div><div class="line">        report = str()</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> items:</div><div class="line">            <span class="keyword">if</span> (<span class="string">u'XX'</span>.encode(<span class="string">"UTF-8"</span>) == i[<span class="number">0</span>]) :</div><div class="line">                <span class="comment"># <span class="doctag">NOTE:</span> u'XX' is a unicode, not a string.</span></div><div class="line">                <span class="comment"># so it must be converted to a UTF-8 character string,</span></div><div class="line">		<span class="comment"># before compared to strarea</span></div><div class="line"></div><div class="line">                <span class="comment"># for debugging it could be printed on the screen, like below</span></div><div class="line">                <span class="keyword">print</span> <span class="string">", "</span>.join(i)</div><div class="line">                report = report + <span class="string">", "</span>.join(i) + <span class="string">"\n"</span></div><div class="line">                </div><div class="line">            <span class="keyword">else</span> :</div><div class="line">                <span class="keyword">pass</span>    </div><div class="line"></div><div class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</div><div class="line">        filename = <span class="string">'ahopper-%s.html'</span> % page </div><div class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f :</div><div class="line">            f.write(report)</div></pre></td></tr></table></figure>
<p>Execute it:</p>
<pre><code>$ scrapy crawl ahopper
</code></pre><h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><h2 id="1-Scrapy-shell"><a href="#1-Scrapy-shell" class="headerlink" title="1. Scrapy shell"></a>1. Scrapy shell</h2><p>Fetch a page:</p>
<pre><code>$ scrapy shell &apos;http://DOMAIN/page/1/&apos;
</code></pre><p>Select a CSS element (ex) ‘title’), and get its text:</p>
<pre><code>&gt;&gt;&gt; response.css(&apos;title&apos;)
[&lt;Selector xpath=&apos;descendant-or-self::title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;
&gt;&gt;&gt; response.css(&apos;title&apos;).extract()
[&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;]
&gt;&gt;&gt; response.css(&apos;title::text&apos;).extract()
[&apos;Quotes to Scrape&apos;]
</code></pre><p>we can use regular expressions:</p>
<pre><code>&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;Quotes.*&apos;)
[&apos;Quotes to Scrape&apos;]
&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;Q\w+&apos;)
[&apos;Quotes&apos;]
&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;(\w+) to (\w+)&apos;)
[&apos;Quotes&apos;, &apos;Scrape&apos;]
</code></pre><p>XPath is supported:</p>
<pre><code>&gt;&gt;&gt; response.xpath(&apos;//title&apos;)
[&lt;Selector xpath=&apos;//title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]
&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract_first()
&apos;Quotes to Scrape&apos;
</code></pre><h1 id="Possible-errors"><a href="#Possible-errors" class="headerlink" title="Possible errors:"></a>Possible errors:</h1><pre><code>[scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
</code></pre><p>then set the following in the settings.py file</p>
<pre><code>ROBOTSTXT_OBEY=false
</code></pre><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul>
<li><a href="https://doc.scrapy.org/en/latest/intro/tutorial.html" target="_blank" rel="external">https://doc.scrapy.org/en/latest/intro/tutorial.html</a></li>
<li><a href="http://www.olafdietsche.de/2015/04/05/extracting-table-data-with-scrapy" target="_blank" rel="external">http://www.olafdietsche.de/2015/04/05/extracting-table-data-with-scrapy</a></li>
<li><a href="http://vnthf.logdown.com/posts/2016/03/18/650623" target="_blank" rel="external">http://vnthf.logdown.com/posts/2016/03/18/650623</a></li>
<li>Scrapy.Items: <a href="https://doc.scrapy.org/en/latest/topics/items.html" target="_blank" rel="external">https://doc.scrapy.org/en/latest/topics/items.html</a></li>
</ul>
<h1 id="ETC"><a href="#ETC" class="headerlink" title="ETC"></a>ETC</h1><ul>
<li>the example code above: <a href="./data/mycrawler.tar.gz">code</a></li>
</ul>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/python/">python</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/python/">python</a>, <a href="/tags/scrapy/">scrapy</a>, <a href="/tags/crawler/">crawler</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Kommentare</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://aintahydra.github.io/2017/11/08/wrting-python-crawlers/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="q" value="site:aintahydra.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Kategorien</h3>
  <ul class="entry">
  
    <li><a href="/categories/ETC/">ETC</a><small>1</small></li>
  
    <li><a href="/categories/TPM/">TPM</a><small>2</small></li>
  
    <li><a href="/categories/emacs/">emacs</a><small>3</small></li>
  
    <li><a href="/categories/python/">python</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/TAGS/">TAGS</a><small>1</small></li>
  
    <li><a href="/tags/TPM/">TPM</a><small>2</small></li>
  
    <li><a href="/tags/TSS/">TSS</a><small>1</small></li>
  
    <li><a href="/tags/Trusted-Platform-Module/">Trusted Platform Module</a><small>1</small></li>
  
    <li><a href="/tags/auctex/">auctex</a><small>1</small></li>
  
    <li><a href="/tags/compute-stick/">compute stick</a><small>1</small></li>
  
    <li><a href="/tags/crawler/">crawler</a><small>1</small></li>
  
    <li><a href="/tags/ctag/">ctag</a><small>1</small></li>
  
    <li><a href="/tags/emacs/">emacs</a><small>3</small></li>
  
    <li><a href="/tags/etag/">etag</a><small>1</small></li>
  
    <li><a href="/tags/gdb/">gdb</a><small>1</small></li>
  
    <li><a href="/tags/latex/">latex</a><small>1</small></li>
  
    <li><a href="/tags/python/">python</a><small>1</small></li>
  
    <li><a href="/tags/scrapy/">scrapy</a><small>1</small></li>
  
    <li><a href="/tags/xpath/">xpath</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 aintahydra
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
